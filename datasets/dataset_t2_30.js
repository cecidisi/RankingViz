function getDataset_t2_30() {

    return {
        "query":"robots",
        "dataset-id" : "T2-30",
        "description" : "Topic 2 - 30 items Ro",
        "text": "General-purpose autonomous robots can perform a variety of functions independently. General-purpose autonomous robots typically can navigate independently in known spaces, handle their own re-charging needs, interface with electronic doors and elevators and perform other basic tasks. Like computers, general-purpose robots can link with networks, software and accessories that increase their usefulness. They may recognize people or objects, talk, provide companionship, monitor environmental quality, respond to alarms, pick up supplies and perform other useful tasks. General-purpose robots may perform a variety of functions simultaneously or they may take on different roles at different times of day. Some such robots try to mimic human beings and may even resemble people in appearance; this type of robot is called a humanoid robot. Humanoid robots are still in a very limited stage, as no humanoid robot can, as of yet, actually navigate around a room that it has never been in. Thus, humanoid robots are really quite limited, despite their intelligent behaviors in their well-known environments.",
        "task": "Considering the given text, select the 5 most relevant items from the list",
        "totalResults":"60",
        "data": [
                    {
                        "id": "00b85ff1-e525-3a0e-9e51-e25da8f14afe",
                        "title": "Autonomous robots : from biological inspiration to implementation and control",
                        "uri": "http://www.mendeley.com/catalog/autonomous-robots-biological-inspiration-implementation-control/",
                        "eexcessURI": "http://www.mendeley.com/catalog/autonomous-robots-biological-inspiration-implementation-control/",
                        "creator": "George A Bekey",
                        "description": "Autonomous robots are intelligent machines capable of performing tasks in the world by themselves, without explicit human control. Examples range from autonomous helicopters to Roomba, the robot vacuum cleaner. In this book, George Bekey offers an introduction to the science and practice of autonomous robots that can be used both in the classroom and as a reference for industry professionals. He surveys the hardware implementations of more than 300 current systems, reviews some of their application areas, and examines the underlying technology, including control, architectures, learning, manipulation, grasping, navigation, and mapping. Living systems can be considered the prototypes of autonomous systems, and Bekey explores the biological inspiration that forms the basis of many recent developments in robotics. He also discusses robot control issues and the design of control architectures. After an overview of the field that introduces some of its fundamental concepts, the book presents background material on hardware, control (from both biological and engineering perspectives), software architecture, and robot intelligence. It then examines a broad range of implementations and applications, including locomotion (wheeled, legged, flying, swimming, and crawling robots), manipulation (both arms and hands), localization, navigation, and mapping. The many case studies and specific applications include robots built for research, industry, and the military, among them underwater robotic vehicles, walking machines with four, six, and eight legs, and the famous humanoid robots Cog, Kismet, ASIMO, and QRIO. The book concludes with reflections on the future of robotics -- the potential benefits as well as the possible dangers that may arise from large numbers of increasingly intelligent and autonomous robots.",
                        "collectionName": "Communication",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2005"
                        },
                    },
                    {
                        "id": "f5924a79-f750-34df-95c8-6dea4baa01ff",
                        "title": "Towards cooperation of heterogeneous, autonomous robots: A case study of humanoid and wheeled robots",
                        "uri": "http://www.mendeley.com/catalog/towards-cooperation-heterogeneous-autonomous-robots-case-study-humanoid-wheeled-robots/",
                        "eexcessURI": "http://www.mendeley.com/catalog/towards-cooperation-heterogeneous-autonomous-robots-case-study-humanoid-wheeled-robots/",
                        "creator": "Jutta Kiener, Oskar Von Stryk",
                        "description": "In this paper a case study of the cooperation of a strongly heterogeneous autonomous robot team, composed of a highly articulated humanoid robot and a wheeled robot with largely complementing and some redundant abilities is presented. By combining strongly heterogeneous robots the diversity of achievable tasks increases as the variety of sensing and motion abilities of the robot system is extended, compared to a usually considered team of homogeneous robots. A number of methodologies and technologies required in order to achieve the long-term goal of cooperation of heterogeneous autonomous robots are discussed, including modeling tasks and robot abilities, task assignment and redistribution, robot behavior modeling and programming, robot middleware and robot simulation. Example solutions and their application to the cooperation of autonomous wheeled and humanoid robots are presented in this case study. The scenario describes a tightly coupled cooperative task, where the humanoid robot and the wheeled robot track a moving ball, which is to be approached and kicked by the humanoid robot into a goal. The task can be fulfilled successfully by combining the abilities of both robots. ?? 2010 Elsevier B.V. All rights reserved.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2010"
                        },
                    },
                    {
                        "id": "cacd96a9-2489-3ab9-9801-befef8b5848b",
                        "title": "Introduction to Autonomous Mobile Robots",
                        "uri": "http://www.mendeley.com/catalog/introduction-autonomous-mobile-robots-50/",
                        "eexcessURI": "http://www.mendeley.com/catalog/introduction-autonomous-mobile-robots-50/",
                        "creator": "Roland Siegwart, Illah R Nourbakhsh",
                        "description": "Mobile robots range from the teleoperated Sojourner on the Mars Pathfinder mission to cleaning robots in the Paris Metro. Introduction to Autonomous Mobile Robots offers students and other interested readers an overview of the technology of mobility the mechanisms that allow a mobile robot to move through a real world environment to perform its tasksincluding locomotion, sensing, localization, and motion planning. It discusses all facets of mobile robotics, including hardware design, wheel design, kinematics analysis, sensors and perception, localization, mapping, and robot control architectures.The design of any successful robot involves the integration of many different disciplines, among them kinematics, signal analysis, information theory, artificial intelligence, and probability theory. Reflecting this, the book presents the techniques and technology that enable mobility in a series of interacting modules. Each chapter covers a different aspect of mobility, as the book moves from low-level to high-level details. The first two chapters explore low-level locomotory ability, examining robots' wheels and legs and the principles of kinematics. This is followed by an in-depth view of perception, including descriptions of many \"off-the-shelf\" sensors and an analysis of the interpretation of sensed data. The final two chapters consider the higher-level challenges of localization and cognition, discussing successful localization strategies, autonomous mapping, and navigation competence. Bringing together all aspects of mobile robotics into one volume, Introduction to Autonomous Mobile Robots can serve as a textbook for coursework or a working tool for beginners in the field.",
                        "collectionName": "Robotica",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2004"
                        },
                    },
                    {
                        "id": "220f6b4b-cf7f-3860-abd5-f4688cd4727f",
                        "title": "Autonomous driving in a multi-level parking structure",
                        "uri": "http://www.mendeley.com/catalog/autonomous-driving-multilevel-parking-structure/",
                        "eexcessURI": "http://www.mendeley.com/catalog/autonomous-driving-multilevel-parking-structure/",
                        "creator": "Rainer Kümmerle, Dirk Hähnel, Dmitri Dolgov, Sebastian Thrun, Wolfram Burgard",
                        "description": "Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",
                        "collectionName": "Proceedings - IEEE International Conference on Robotics and Automation",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2009"
                        },
                    },
                     {
                        "id": "6dfc7297-c206-3b5d-a78d-249ff1eda690",
                        "title": "Individual and cooperative tasks performed by autonomous MAV teams driven by embodied neural network controllers",
                        "uri": "http://www.mendeley.com/catalog/individual-cooperative-tasks-performed-autonomous-mav-teams-driven-embodied-neural-network-controlle/",
                        "eexcessURI": "http://www.mendeley.com/catalog/individual-cooperative-tasks-performed-autonomous-mav-teams-driven-embodied-neural-network-controlle/",
                        "creator": "Fabio Ruini, Angelo Cangelosi, Franck Zetule",
                        "description": "The work presented here focuses on the use of embodied neural network controllers for MAV (micro-unmanned aerial vehicles) teams. The computer model we have built aims to demonstrate how autonomous controllers for groups of flying robots can be successfully developed through simulations based on multi-agent systems and evolutionary robotics methodologies. We first introduce the field of autonomous flying robots, reviewing the most relevant contributes on this research field and highlighting the elements of novelty contained in our approach. We then describe the simulation model we have elaborated and the results obtained in different experimental scenarios. In all experiments, MAV teams made by four agents have to navigate autonomously through an unknown environment, reach a certain target and finally neutralize it through a self-detonation. The different setups comprise an environment with various obstacles (skyscrapers) and a fixed target, one with a moving target, and one where the target (fixed or moving) needs to be attacked cooperatively in order to be neutralized. The results obtained show how the evolved controllers are able to perform the various tasks with an accuracy level between 72% and 94% when the target has to be approached individually. The performance slightly decreases only when the target is both able to move and can only be neutralized through a coordinated operation. The paper ends with a discussion on the possible applications of autonomous MAV teams to real life scenarios.",
                        "collectionName": "Proceedings of the International Joint Conference on Neural Networks",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2009"
                        },
                    },
                    {
                        "id": "6c015590-e2bd-391f-a9c0-07d35ff28037",
                        "title": "Adaptive LEGO robots. A robot=human view on robotics",
                        "uri": "http://www.mendeley.com/catalog/adaptive-lego-robots-robothuman-view-robotics/",
                        "eexcessURI": "http://www.mendeley.com/catalog/adaptive-lego-robots-robothuman-view-robotics/",
                        "creator": "H.H. Lund, C. Bjerre, J.H. Nielsen, M. Nielsen, K. Stoy",
                        "description": "In many applications, robots are viewed as a machine. This has resulted in interaction and actuation which is characteristic for machines. When constructing adaptive LEGO robots, we take another view, namely that the robot should resemble a human (or a biological creature) rather than a machine. This has implications on the interaction, actuation and control of the robot. I describe how the robot-as-human approach is investigated in a number of LEGO Mindstorms robot applications. These include making facial expressions, which allows a LEGO robot to express internal &amp;ldquo;moods&amp;rdquo;, and thereby we might achieve a better human-robot interaction. Another application is the Adaptive LEGO Pet Robot. The Adaptive LEGO Pet Robot's control is based on a modular behaviour system, where a number of the modules are evolved neural networks. Further, the Adaptive LEGO Pet Robot has a number of internal drives such as restlessness and hunger, which allow the robot to react on the internal drives. The human-robot interaction is facilitated by allowing the human to train the LEGO pet robot (rather than to program the robot) to make associations between spoken words (via speech recognition) and evolved behaviour. The Adaptive LEGO Pet Robot is an example of scaling up evolutionary robotics to complex behaviour by combining evolutionary robotics with behaviour-based robotics",
                        "collectionName": "IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",
                        "facets": {
                            "provider": "mendeley",
                            "year": "1999"
                        },
                    },
                    {
                        "id": "14053480-ecd3-3374-9566-b78c137cb516",
                        "title": "Theory and evaluation of human robot interactions",
                        "uri": "http://www.mendeley.com/catalog/theory-evaluation-human-robot-interactions-20/",
                        "eexcessURI": "http://www.mendeley.com/catalog/theory-evaluation-human-robot-interactions-20/",
                        "creator": "Jean Scholtz",
                        "description": "Human-robot interaction (HRI) for mobile robots is still in its infancy. Most user interactions with robots have been limited to tele-operation capabilities where the most common interface provided to the user has been the video feed from the robotic platform and some way of directing the path of the robot. Control systems exhibit autonomy and cognition, and which operate in changing, real-world environments. In addition For mobile robots with semi-autonomous capabilities, the user is also provided with a means of setting way points. More importantly, most HRI capabilities have been developed by robotics experts for use by robotics experts. As robots increase in capabilities and are able to perform more tasks in an autonomous manner we need to think about the interactions that humans will have with robots and what software architecture and user interface designs can accommodate the human in-the-loop. We also need to design systems that can be used by domain experts but not robotics experts. This paper outlines a theory interaction and proposes the interactions of human-robot and information needed by both humans and robots for the different levels of interaction, including an evaluation methodology based on situational awareness.",
                        "collectionName": "36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2003"
                        },
                    },
                    {
                        "id": "8d70f941-335c-389c-9b93-93c059f618c8",
                        "title": "Persuasive robotics: The influence of robot gender on human behavior",
                        "uri": "http://www.mendeley.com/catalog/persuasive-robotics-influence-robot-gender-human-behavior/",
                        "eexcessURI": "http://www.mendeley.com/catalog/persuasive-robotics-influence-robot-gender-human-behavior/",
                        "creator": "Mikey Siegel, Cynthia Breazeal, Michael I. Norton",
                        "description": "Persuasive Robotics is the study of persuasion as it applies to human-robot interaction (HRI). Persuasion can be generally defined as an attempt to change another's beliefs or behavior. The act of influencing others is fundamental to nearly every type of social interaction. Any agent desiring to seamlessly operate in a social manner will need to incorporate this type of core human behavior. As in human interaction, myriad aspects of a humanoid robot's appearance and behavior can significantly alter its persuasiveness - this work will focus on one particular factor: gender. In the current study, run at the Museum of Science in Boston, subjects interacted with a humanoid robot whose gender was varied. After a short interaction and persuasive appeal, subjects responded to a donation request made by the robot, and subsequently completed a post-study questionnaire. Findings showed that men were more likely to donate money to the female robot, while women showed little preference. Subjects also tended to rate the robot of the opposite sex as more credible, trustworthy, and engaging. In the case of trust and engagement the effect was much stronger between male subjects and the female robot. These results demonstrate the importance of considering robot and human gender in the design of HRI.",
                        "collectionName": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2009"
                        },
                    },
                    {
                        "id": "fd94ceab-f501-3b11-9608-e531281436c9",
                        "title": "Prediction of human behavior in human-robot interaction using psychological scales for anxiety and negative attitudes toward robots",
                        "uri": "http://www.mendeley.com/catalog/prediction-human-behavior-human-robot-interaction-using-psychological-scales-anxiety-negative-attitu/",
                        "eexcessURI": "http://www.mendeley.com/catalog/prediction-human-behavior-human-robot-interaction-using-psychological-scales-anxiety-negative-attitu/",
                        "creator": "Tatsuya Nomura, Takayuki Kanda, Tomohiro Suzuki, Kensuke Kato",
                        "description": "When people interact with communication robots in daily life, their attitudes and emotions toward the robots affect their behavior. From the perspective of robotics design, we need to investigate the influences of these attitudes and emotions on human-robot interaction. This paper reports our empirical study on the relationships between people's attitudes and emotions, and their behavior toward a robot. In particular, we focused on negative attitudes, anxiety, and communication avoidance behavior, which have important implications for robotics design. For this purpose, we used two psychological scales that we had developed: negative attitudes toward robots scale (NARS) and robot anxiety scale (RAS). In the experiment, subjects and a humanoid robot are engaged in simple interactions including scenes of meeting, greeting, self-disclosure, and physical contact. Experimental results indicated that there is a relationship between negative attitudes and emotions, and communication avoidance behavior. A gender effect was also suggested.",
                        "collectionName": "IEEE Transactions on Robotics",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2008"
                        },
                    },
                    {
                        "id": "9d7919af-ac48-312e-ac78-c8880ad0a301",
                        "title": "Learning about natural human-robot interaction styles",
                        "uri": "http://www.mendeley.com/catalog/learning-about-natural-humanrobot-interaction-styles/",
                        "eexcessURI": "http://www.mendeley.com/catalog/learning-about-natural-humanrobot-interaction-styles/",
                        "creator": "Tamie Salter, Kerstin Dautenhahn, René Te Boekhorst",
                        "description": "If we are to achieve natural human-robot interaction, we may need to complement current vision and speech interfaces. Touch may provide us with an extra tool in this quest. In this paper we demonstrate the role of touch in interaction between a robot and a human. We show how infrared sensors located on robots can be easily used to detect and distinguish human interaction, in this case interaction with individual children. This application of infrared sensors potentially has many uses; for example, in entertainment or service robotics. This system could also benefit therapy or rehabilitation, where the observation and recording of movement and interaction is important. In the long term, this technique might enable robots to adapt to individuals or individual types of user.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2006"
                        },
                    },
                    {
                        "id": "4f99d039-2b7e-3159-a422-a6d9c264ad28",
                        "title": "Social interactions in HRI: The robot view",
                        "uri": "http://www.mendeley.com/catalog/social-interactions-hri-robot-view/",
                        "eexcessURI": "http://www.mendeley.com/catalog/social-interactions-hri-robot-view/",
                        "creator": "Cynthia Breazeal",
                        "description": "This paper explores the topic of human-robot interaction (HRI) from the perspective of designing sociable autonomous robots - robots designed to interact with people in a human-like way-. There are a growing number of applications for robots that people can engage as capable creatures or as partners rather than tools, yet little is understood about how to best design robots that interact with people in this way. The related field of human-computer interaction (HCI) offers important insights, however autonomous robots are a very different technology from desktop computers. In this paper, we look at the field of HRI from an HCI perspective, pointing out important similarities yet significant differences that may ultimately make HRI a distinct area of inquiry. One outcome of this discussion is that it is important to view the design and evaluation problem from the robot's perspective as well as that of the human. Taken as a whole, this paper provides a framework with which to design and evaluate sociable robots from a HRI perspective.",
                        "collectionName": "IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2004"
                        },
                    },
                    {
                        "id": "6c52238b-367f-3587-8c45-9b1b062ad3d8",
                        "title": "Human-robot communication for collaborative decision making - A probabilistic approach",
                        "uri": "http://www.mendeley.com/research/humanrobot-communication-collaborative-decision-making-probabilistic-approach/",
                        "eexcessURI": "http://www.mendeley.com/research/humanrobot-communication-collaborative-decision-making-probabilistic-approach/",
                        "creator": "Tobias Kaupp, Alexei Makarenko, Hugh Durrant-Whyte",
                        "description": "Humans and robots need to exchange information if the objective is to achieve a task collaboratively. Two questions are considered in this paper: what and when to communicate. To answer these questions, we developed a human-robot communication framework which makes use of common probabilistic robotics representations. The data stored in the representation determines what to communicate, and probabilistic inference mechanisms determine when to communicate. One application domain of the framework is collaborative human-robot decision making: robots use decision theory to select actions based on perceptual information gathered from their sensors and human operators. In this paper, operators are regarded as remotely located, valuable information sources which need to be managed carefully. Robots decide when to query operators using Value-Of-Information theory, i.e. humans are only queried if the expected benefit of their observation exceeds the cost of obtaining it. This can be seen as a mechanism for adjustable autonomy whereby adjustments are triggered at run-time based on the uncertainty in the robots' beliefs related to their task. This semi-autonomous system is demonstrated using a navigation task and evaluated by a user study. Participants navigated a robot in simulation using the proposed system and via classical teleoperation. Results show that our system has a number of advantages over teleoperation with respect to performance, operator workload, usability, and the users' perception of the robot. We also show that despite these advantages, teleoperation may still be a preferable driving mode depending on the mission priorities. Crown Copyright ?? 2010.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2010"
                        },
                    },
                    {
                        "id": "1eaeb7ea-0381-357d-b836-daa8028d4a33",
                        "title": "Human-robot interaction in rescue robotics",
                        "uri": "http://www.mendeley.com/catalog/humanrobot-interaction-rescue-robotics/",
                        "eexcessURI": "http://www.mendeley.com/catalog/humanrobot-interaction-rescue-robotics/",
                        "creator": "Robin Roberson Murphy",
                        "description": "Rescue robotics has been suggested by a recent DARPA/NSF study as an application domain for the research in human-robot integration (HRI). This paper provides a short tutorial on how robots are currently used in urban search and rescue (USAR) and discusses the HRI issues encountered over the past eight years. A domain theory of the search activity is formulated. The domain theory consists of two parts: 1) a workflow model identifying the major tasks, actions, and roles in robot-assisted search (e.g., a workflow model) and 2) a general information flow model of how data from the robot is fused by various team members into information and knowledge. The information flow model also captures the types of situation awareness needed by each agent in the rescue robot system. The article presents a synopsis of the major HRI issues in reducing the number of humans it takes to control a robot, maintaining performance with geographically distributed teams with intermittent communications, and encouraging acceptance within the existing social structure.",
                        "collectionName": "IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2004"
                        },
                    },
                    {
                        "id": "9042dc56-5cd2-3148-9d81-c1c97e24fd20",
                        "title": "A survey of socially interactive robots",
                        "uri": "http://www.mendeley.com/catalog/survey-socially-interactive-robots/",
                        "eexcessURI": "http://www.mendeley.com/catalog/survey-socially-interactive-robots/",
                        "creator": "Terrence Fong, Illah Nourbakhsh, Kerstin Dautenhahn",
                        "description": "This paper reviews \"socially interactive robots\": robots for which social human-robot interaction is important. We begin by discussing the context for socially interactive robots, emphasizing the relationship to other research fields and the different forms of \"social robots\". We then present a taxonomy of design methods and system components used to build socially interactive robots. Finally, we describe the impact of these robots on humans and discuss open issues. An expanded version of this paper, which contains a survey and taxonomy of current applications, is available as a technical report [T. Fong, I. Nourbakhsh, K. Dautenhahn, A survey of socially interactive robots: concepts, design and applications, Technical Report No. CMU-RI-TR-02-29, Robotics Institute, Carnegie Mellon University, 2002]. ?? 2003 Elsevier Science B.V. All rights reserved.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2003"
                        },
                    },
                    {
                        "id": "4ef8d4ea-8b4a-379d-85af-91b929ffdc57",
                        "title": "Can robots be teammates?: Benchmarks in human–robot teams.",
                        "uri": "http://www.mendeley.com/catalog/robots-teammates-benchmarks-humanrobot-teams/",
                        "eexcessURI": "http://www.mendeley.com/catalog/robots-teammates-benchmarks-humanrobot-teams/",
                        "creator": "Victoria Groom, Clifford Nass",
                        "description": "The team has become a popular model to organize joint human–robot behavior. Robot teammates are designed with high-levels of autonomy and well-developed coordination skills to aid humans in unpredictable environments. In this paper, we challenge the assumption that robots will succeed as teammates alongside humans. Drawing from the literature on human teams, we evaluate robots’ po- tential to meet the requirements of successful teammates. We argue that lacking humanlike mental models and a sense of self, robots may prove untrustworthy and will be rejected from human teams. Benchmarks for evaluating human–robot teams are included, as are guidelines for defining alternative structures for human–robot groups.",
                        "collectionName": "Interaction Studies",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2007"
                        },
                    },
                    {
                        "id": "8846edd2-db8d-3315-a690-6482ef02c323",
                        "title": "Surgical robotics",
                        "uri": "http://www.mendeley.com/catalog/surgical-robotics-1/",
                        "eexcessURI": "http://www.mendeley.com/catalog/surgical-robotics-1/",
                        "creator": "Ron Alterovitz, Jaydev P. Desai",
                        "description": "Surgical robotics is experiencing an explosion of growth in both academic and clinical settings. Since the first reported robotic surgical procedure two decades ago, surgical robotics has grown into more than a half billion dollar a year industry, and robots are now being used in thousands of surgical procedures each year. One especially successful commercial robot, Intuitive Surgical's da Vinci system for laparoscopic procedures, has been installed worldwide in more than 1,000 locations. This growth is a direct result of the promise of surgical robots to improve patient care. Integration of robot hardware with computer-integrated surgical systems has the potential to enable precise, targeted, minimally invasive medical interventions. Robotic devices are enabling physicians to perform procedures with reduced trauma, less blood loss, fewer errors, and faster patient recovery than would otherwise be possible. Robotics technology can also enhance the effectiveness of clinical procedures by coupling information sources such as medical images to actions in the operating room.",
                        "collectionName": "IEEE Robotics and Automation Magazine",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2009"
                        },
                    },
            		{
                        "id": "40ad8325-d0ef-3743-8b16-a822b77678fe",
                        "title": "CONRO: towards deployable robots with inter-robot metamorphic capabilities",
                        "uri": "http://www.mendeley.com/catalog/conro-towards-deployable-robots-interrobot-metamorphic-capabilities/",
                        "eexcessURI": "http://www.mendeley.com/catalog/conro-towards-deployable-robots-interrobot-metamorphic-capabilities/",
                        "creator": "Andres Castano, Wei Min Shen, Peter Will",
                        "description": "Metamorphic robots are modular robots that can reconfigure their shape. Such capability is desirable in tasks such as earthquake search and rescue and battlefield surveillance and scouting, where robots must go through unexpected situations and obstacles and perform tasks that are difficult for fixed-shape robots. The capabilities of the robots are determined by the design specification of their modules. In this paper, we present the design specification of a CONRO module, a small, self-sufficient and relatively homogeneous module that can be connected to other modules to form complex robots. These robots have not only the capability of changing their shape (intra-robot metamorphing) but also can split into smaller robots or merge with other robots to create a single larger robot (inter-robot metamorphing), i.e., CONRO robots can alter their shape and their size. Thus, heterogeneous robot teams can be built with homogeneous components. Furthermore, the CONRO robots can separate the reconfiguration stage from the locomotion stage, allowing the selection of configuration-dependent gaits. The locomotion and automatic inter-module docking capabilities of such robots were tested using tethered prototypes that can be reconfigured manually. We conclude the paper discussing the future work needed to fully realize the construction of these robots.",
                        "collectionName": "Autonomous Robots",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2000"
                        },
                    },
                    {
                        "id": "8cb36c03-075a-3b45-9143-d924ff92e633",
                        "title": "Fitness functions in evolutionary robotics: A survey and analysis",
                        "uri": "http://www.mendeley.com/catalog/fitness-functions-evolutionary-robotics-survey-analysis/",
                        "eexcessURI": "http://www.mendeley.com/catalog/fitness-functions-evolutionary-robotics-survey-analysis/",
                        "creator": "Andrew L. Nelson, Gregory J. Barlow, Lefteris Doitsidis",
                        "description": "This paper surveys fitness functions used in the field of evolutionary robotics (ER). Evolutionary robotics is a field of research that applies artificial evolution to generate control systems for autonomous robots. During evolution, robots attempt to perform a given task in a given environment. The controllers in the better performing robots are selected, altered and propagated to perform the task again in an iterative process that mimics some aspects of natural evolution. A key component of this process-one might argue, the key component-is the measurement of fitness in the evolving controllers. ER is one of a host of machine learning methods that rely on interaction with, and feedback from, a complex dynamic environment to drive synthesis of controllers for autonomous agents. These methods have the potential to lead to the development of robots that can adapt to uncharacterized environments and which may be able to perform tasks that human designers do not completely understand. In order to achieve this, issues regarding fitness evaluation must be addressed. In this paper we survey current ER research and focus on work that involved real robots. The surveyed research is organized according to the degree of a priori knowledge used to formulate the various fitness functions employed during evolution. The underlying motivation for this is to identify methods that allow the development of the greatest degree of novel control, while requiring the minimum amount of a priori task knowledge from the designer. ?? 2008 Elsevier B.V. All rights reserved.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2009"
                        },
                    },
                    {
                        "id": "27d8886d-a4be-3554-8a39-0c1451e5818f",
                        "title": "Adaptive navigation for autonomous robots",
                        "uri": "http://www.mendeley.com/catalog/adaptive-navigation-autonomous-robots/",
                        "eexcessURI": "http://www.mendeley.com/catalog/adaptive-navigation-autonomous-robots/",
                        "creator": "Matt Knudson, Kagan Tumer",
                        "description": "In many robotic exploration missions, robots have to learn specific policies that allow them to: (i) select high level goals (e.g., identify specific destinations), (ii) navigate (reach those destinations), (iii) and adapt to their environment (e.g., modify their behavior based on changing environmental conditions). Furthermore, those policies must be robust to signal noise or unexpected situations, scalable to more complex environments, and account for the physical limitations of the robots (e.g., limited battery power and computational power). In this paper we evaluate reactive and learning navigation algorithms for exploration robots that must avoid obstacles and reach specific destinations in limited time and with limited observations. Our results show that neuro-evolutionary algorithms with well-designed evaluation functions can produce up to 50% better performance than reactive algorithms in complex domains where the robot's goals are to select paths that lead to seek specific destinations while avoiding obstacles, particularly when facing significant sensor and actuator signal noise. ?? 2011 Elsevier B.V. All rights reserved.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2011"
                        },
                    },
                    {
                        "id": "33c4e6a4-4587-3188-b7ca-42addf007c74",
                        "title": "Reem-B: An autonomous lightweight human-size humanoid robot",
                        "uri": "http://www.mendeley.com/catalog/reemb-autonomous-lightweight-humansize-humanoid-robot/",
                        "eexcessURI": "http://www.mendeley.com/catalog/reemb-autonomous-lightweight-humansize-humanoid-robot/",
                        "creator": "Ricardo Tellez, Francesco Ferro, Sergio Garcia, Esteban Gomez, Enric Jorge, Dario Mora, Daniel Pinyol, Joan Oliver, Oriol Torres, Jorge Velazquez, Davide Faconti",
                        "description": "This paper introduces the humanoid robot Reem-B, built by Pal robotics as a research platform in the field of service robots. The idea is to produce robots that can help humans and cohabit their environments. For this purpose, the body plan, sensory and actuator system of the robot, as well as its cognitive abilities must be designed to perform real-world tasks including dynamic walking, interaction with people or object recognition and manipulation. Reem-B achieves this scope by using two legs, two strong arms with fingered hands, and a software suite that controls all its degrees of freedom, coordinating them with vision and auditory systems. The main difference with other humanoids of its size is its level of autonomy. Autonomy in this robot has been improved from other robots at three different levels: with an increased battery life (estimated twice of the competitors), with the ability to autonomously navigate in indoor environments while avoiding obstacles, and by integrating all the control systems within the robot itself.",
                        "collectionName": "2008 8th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2008",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2008"
                        },
                    },
                    {
                        "id": "0fc99ddb-887c-3359-88c0-adb823da9c45",
                        "title": "Real time gait generation for autonomous humanoid robots: A case study for walking",
                        "uri": "http://www.mendeley.com/catalog/real-time-gait-generation-autonomous-humanoid-robots-case-study-walking/",
                        "eexcessURI": "http://www.mendeley.com/catalog/real-time-gait-generation-autonomous-humanoid-robots-case-study-walking/",
                        "creator": "Genci Capi, Yasuo Nasu, Leonard Barolli, Kazuhitsa Mitobe",
                        "description": "As autonomous humanoid robots assume more important roles in everyday life, they are expected to perform many different tasks and quickly adapt to unknown environments. Therefore, humanoid robots must generate quickly the appropriate gait based on information received from visual system. In this work, we present a new method for real time gait generation during walking based on Neural Networks. The minimum consumed energy gaits similar with human motion, are used to teach the Neural Network. After supervised learning, the Neural Network can quickly generate the humanoid robot gait. Simulation and experimental results utilizing the \"Bonten-Maru I\" humanoid robot show good performance of the proposed method. ?? 2002 Elsevier Science B.V. All rights reserved.",
                        "collectionName": "Robotics and Autonomous Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2003"
                        },
                    },
                    {
                        "id": "5f1f989e-285d-3f2a-8147-f89b26f5cd5b",
                        "title": "Self-assembly on demand in a group of physical autonomous mobile robots navigating rough terrain",
                        "uri": "http://www.mendeley.com/catalog/selfassembly-demand-group-physical-autonomous-mobile-robots-navigating-rough-terrain/",
                        "eexcessURI": "http://www.mendeley.com/catalog/selfassembly-demand-group-physical-autonomous-mobile-robots-navigating-rough-terrain/",
                        "creator": "Rehan O'Grady, Roderich Groß, Francesco Mondada, Michael Bonani, Marco Dorigo",
                        "description": "Consider a group of autonomous, mobile robots with the ability to physically connect to one another (self-assemble). The group is said to exhibit functional self-assembly if the robots can choose to self-assemble in response to the demands of their task and environment. We present the first robotic controller capable of functional self-assembly implemented on a real robotic platform. The task we consider requires a group of robots to navigate over an area of unknown terrain towards a target light source. If possible, the robots should navigate to the target independently. If, however, the terrain proves too difficult for a single robot, the robots should self-assemble into a larger group entity and collectively navigate to the target. We believe this to be one of the most complex tasks carried out to date by a team of physical autonomous robots. We present quantitative results confirming the efficacy of our controller. This puts our robotic system at the cutting edge of autonomous mobile multi-robot research.",
                        "collectionName": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2005"
                        },
                    },
                    {
                        "id": "4060559a-9a90-33b6-9f19-5fc7f913cc62",
                        "title": "The Advisor Robot: Tracing People’s Mental Model from a Robot’s Physical Attributes",
                        "uri": "http://www.mendeley.com/catalog/advisor-robot-tracing-peoples-mental-model-robots-physical-attributes/",
                        "eexcessURI": "http://www.mendeley.com/catalog/advisor-robot-tracing-peoples-mental-model-robots-physical-attributes/",
                        "creator": "Aaron Powers, Aaron Powers, Sara Kiesler, Sara Kiesler",
                        "description": " Humanoid robots offer many physical design choices such as voice frequency and head dimensions. We used hierarchical statistical mediation analysis to trace differences in people's mental model of robots from these choices. In an experiment, a humanoid robot gave participants online advice about their health. We used mediation analysis to identify the causal path from the robot's voice and head dimensions to the participants' mental model, and to their willingness to follow the robot's advice. The male robot voice predicted impressions of a knowledgeable robot, whose advice participants said they would follow. Increasing the voice's fundamental frequency reduced this effect. The robot's short chin length (but not its forehead dimensions) predicted impressions of a sociable robot, which also predicted intentions to take the robot's advice. We discuss the use of this approach for designing robots for different roles, when people's mental model of the robot matters. ",
                        "collectionName": "HRI '06: Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2006"
                        },
                    },
                    {
                        "id": "d8a8c10b-69f3-388a-adc9-ed0331bc40a9",
                        "title": "Discussion of Challenges for User Interfaces in Human-Robot Teams",
                        "uri": "http://www.mendeley.com/research/discussion-challenges-user-interfaces-humanrobot-teams/",
                        "eexcessURI": "http://www.mendeley.com/research/discussion-challenges-user-interfaces-humanrobot-teams/",
                        "creator": "F Driewer, M Sauer, K Schilling",
                        "description": "This paper describes the challenges for user interfaces in human-robot teams and elaborates requirements considering the different roles that human can take over in such teams. The implementation of various test interfaces and observations from experiments support the claimed requirements. The discussed human-robot teams consist of a remote supervisor and several team members (humans and robots) in the workspace. Humans and robots incorporate their different capabilities into the team for the accomplishment of a common goal. The supervisor guides the team and monitors the overall situation. The humans in the workspace work side-by-side with the robots and interact with them as peers. \nIndex Terms  Human-robot interaction (HRI), Human-robot teams, teleoperation, user interfaces.",
                        "collectionName": "ECMR 2007",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2007"
                        },
                    },
                    {
                        "id": "c656a765-310f-3904-bfed-108687a9b313",
                        "title": "Can we talk to robots? Ten-month-old infants expected interactive humanoid robots to be talked to by persons",
                        "uri": "http://www.mendeley.com/catalog/we-talk-robots-tenmonthold-infants-expected-interactive-humanoid-robots-talked-persons/",
                        "eexcessURI": "http://www.mendeley.com/catalog/we-talk-robots-tenmonthold-infants-expected-interactive-humanoid-robots-talked-persons/",
                        "creator": "Akiko Arita, Kazuo Hiraki, Takayuki Kanda, Hiroshi Ishiguro",
                        "description": "As technology advances, many human-like robots are being developed. Although these humanoid robots should be classified as objects, they share many properties with human beings. This raises the question of how infants classify them. Based on the looking-time paradigm used by [Legerstee, M., Barna, J., & DiAdamo, C., (2000). Precursors to the development of intention at 6 months: understanding people and their actions. Developmental Psychology, 36, 5, 627-634.], we investigated whether 10-month-old infants expected people to talk to a humanoid robot. In a familiarization period, each infant observed an actor and an interactive robot behaving like a human, a non-interactive robot remaining stationary, and a non-interactive robot behaving like a human. In subsequent test trials, the infants were shown another actor talking to the robot and to the actor. We found that infants who had previously observed the interactive robot showed no difference in looking-time between the two types of test events. Infants in the other conditions, however, looked longer at the test event where the second experimenter talked to the robot rather than where the second experimenter talked to the person. These results suggest that infants interpret the interactive robot as a communicative agent and the non-interactive robot as an object. Our findings imply that infants categorize interactive humanoid robots as a kind of human being. ?? 2004 Elsevier B.V. All rights reserved.",
                        "collectionName": "Cognition",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2005"
                        },
                    },
                    {
                        "id": "807ffc6f-2186-3ff8-abc3-00e5c14bfbc1",
                        "title": "Is imitation learning the route to humanoid robots?",
                        "uri": "http://www.mendeley.com/catalog/imitation-learning-route-humanoid-robots/",
                        "eexcessURI": "http://www.mendeley.com/catalog/imitation-learning-route-humanoid-robots/",
                        "creator": "Stefan Schaal",
                        "description": "This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It is postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in the form of movement primitives. It is reviewed here how research on representations of, and functional connections between, action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation. Computational approaches to imitation learning are also described, initially from the perspective of traditional Al and robotics, but also from the perspective of neural network models and statistical-learning research. Parallels and differences between biological and computational approaches to imitation are highlighted and an overview of current projects that actually employ imitation learning for humanoid robots is given.",
                        "collectionName": "Trends in Cognitive Sciences",
                        "facets": {
                            "provider": "mendeley",
                            "year": "1999"
                        },
                    },
                    {
                        "id": "4b7acccc-07c5-3080-9822-a9d4a6718158",
                        "title": "The eMOSAIC model for humanoid robot control",
                        "uri": "http://www.mendeley.com/catalog/emosaic-model-humanoid-robot-control/",
                        "eexcessURI": "http://www.mendeley.com/catalog/emosaic-model-humanoid-robot-control/",
                        "creator": "Norikazu Sugimoto, Jun Morimoto, Sang Ho Hyon, Mitsuo Kawato",
                        "description": "In this study, we propose an extension of the MOSAIC architecture to control real humanoid robots. MOSAIC was originally proposed by neuroscientists to understand the human ability of adaptive control. The modular architecture of the MOSAIC model can be useful for solving nonlinear and non-stationary control problems. Both humans and humanoid robots have nonlinear body dynamics and many degrees of freedom. Since they can interact with environments (e.g., carrying objects), control strategies need to deal with non-stationary dynamics. Therefore, MOSAIC has strong potential as a human motor-control model and a control framework for humanoid robots. Yet application of the MOSAIC model has been limited to simple simulated dynamics since it is susceptive to observation noise and also cannot be applied to partially observable systems. Our approach introduces state estimators into MOSAIC architecture to cope with real environments. By using an extended MOSAIC model, we are able to successfully generate squatting and object-carrying behaviors on a real humanoid robot. © 2012 Elsevier Ltd.",
                        "collectionName": "Neural Networks",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2012"
                        },
                    },
                    {
                        "id": "1f10f8b2-7772-3e90-87d4-b984b351d291",
                        "title": "Robotics, motor learning, and neurologic recovery.",
                        "uri": "http://www.mendeley.com/catalog/robotics-motor-learning-neurologic-recovery/",
                        "eexcessURI": "http://www.mendeley.com/catalog/robotics-motor-learning-neurologic-recovery/",
                        "creator": "David J Reinkensmeyer, Jeremy L Emken, Steven C Cramer",
                        "description": "Robotic devices are helping shed light on human motor control in health and injury. By using robots to apply novel force fields to the arm, investigators are gaining insight into how the nervous system models its external dynamic environment. The nervous system builds internal models gradually by experience and uses them in combination with impedance and feedback control strategies. Internal models are robust to environmental and neural noise, generalized across space, implemented in multiple brain regions, and developed in childhood. Robots are also being used to assist in repetitive movement practice following neurologic injury, providing insight into movement recovery. Robots can haptically assess sensorimotor performance, administer training, quantify amount of training, and improve motor recovery. In addition to providing insight into motor control, robotic paradigms may eventually enhance motor learning and rehabilitation beyond the levels possible with conventional training techniques.",
                        "collectionName": "Annual review of biomedical engineering",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2004"
                        },
                    },
                    {
                        "id": "7495ea04-aa4e-3a6b-9a6c-4161d4f28ea6",
                        "title": "The evolution of robotics research",
                        "uri": "http://www.mendeley.com/catalog/evolution-robotics-research/",
                        "eexcessURI": "http://www.mendeley.com/catalog/evolution-robotics-research/",
                        "creator": "Elena Garcia, Maria Antonia Jimenez, Pablo Gonzalez De Santos, Manuel Armada",
                        "description": "This article surveys traditional research topics in industrial robotics and mobile robotics and then expands on new trends in robotics research that focus more on the interaction between human and robot. The new trends in robotics research have been denominated service robotics because of their general goal of getting robots closer to human social needs, and this article surveys research on service robotics such as medical robotics, rehabilitation robotics, underwater robotics, field robotics, construction robotics and humanoid robotics. The aim of this article is to provide an overview of the evolution of research topics in robotics from classical motion control for industrial robots to modern intelligent control techniques and social learning paradigms, among other aspects",
                        "collectionName": "IEEE Robotics and Automation Magazine",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2007"
                        },
                    },
                    {
                        "id": "7abcda18-b9ef-38b9-83c5-4a34992c8610",
                        "title": "Humanoid robot which can lift a 30kg box by whole body contact and tactile feedback",
                        "uri": "http://www.mendeley.com/catalog/humanoid-robot-lift-30kg-box-whole-body-contact-tactile-feedback/",
                        "eexcessURI": "http://www.mendeley.com/catalog/humanoid-robot-lift-30kg-box-whole-body-contact-tactile-feedback/",
                        "creator": "Yoshiyuki Ohmura, Yasuo Kuniyoshi",
                        "description": "We present realization of a humanoid which can lift a heavy object by whole body contact. Most humanoid motions are limited to the posture of the end-effectors only landing. In principle these humanoids can not do natural motion. If a humanoid robot is allowed arbitrary contact with the surrounding objects, it can improve the performance and operate a heavier object. We propose a \"whole body contact motion\" of a humanoid robot. It is defined as a control of contact state of a humanoid robot which has the distributed tactile sensors. We develop conformable and scalable tactile skin and an adult-size humanoid with a smooth surfaces for arbitrary contact. We install the skin on the entire surfaces of the humanoid. Finally we describe the humanoid lifting a 30kg box by tactile feedback.",
                        "collectionName": "IEEE International Conference on Intelligent Robots and Systems",
                        "facets": {
                            "provider": "mendeley",
                            "year": "2007"
                        },
                    }
                ]
    };

}
